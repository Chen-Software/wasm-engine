---
id: ADR-009
title: "Model Caching & GPU Memory Policy"
status: "Proposed"
date: 2025-12-17
related:
  - ADR-001
tags:
  - runtime
  - onnx
  - memory-management
---

# ADR-009: Model Caching & GPU Memory Policy

## 1. Context

[Explain the context and problem statement here. This ADR should define the LRU caching, preloading heuristics, and other policies for managing GPU memory and model loading.]

## 2. Decision

[State the decision clearly. For example, a decision might be to implement an LRU cache for models with a specific size limit and a preloading mechanism based on agent declarations.]

## 3. Rationale

[Explain the reasoning behind the decision. This should cover the trade-offs between memory usage, model loading latency, and overall performance.]

## 4. Consequences

[Describe the positive, negative, and trade-off consequences of the chosen model caching and GPU memory policy.]

## 5. Status

Proposed.
